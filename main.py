#!/usr/bin/env python3
"""
Programme d'analyse des statistiques VÃ©lomagg de Montpellier
Utilise les APIs officielles de Montpellier MÃ©tropole
"""

import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import json
import time
from typing import List, Dict, Any, Optional
import urllib.parse
import os

class VelomaggAnalyzer:
    """Classe principale pour analyser les donnÃ©es VÃ©lomagg"""
    
    BASE_URL = "https://portail-api-data.montpellier3m.fr"
    STATIONS_ENDPOINT = "/bikestation"
    TIMESERIES_ENDPOINT = "/bikestation_timeseries"
    
    def __init__(self):
        self.stations_data = None
        self.timeseries_cache = {}
        
    def get_all_stations(self) -> List[Dict[str, Any]]:
        """RÃ©cupÃ¨re la liste de toutes les stations"""
        try:
            response = requests.get(f"{self.BASE_URL}{self.STATIONS_ENDPOINT}")
            response.raise_for_status()
            self.stations_data = response.json()
            print(f"âœ… RÃ©cupÃ©ration de {len(self.stations_data)} stations")
            return self.stations_data
        except requests.RequestException as e:
            print(f"âŒ Erreur lors de la rÃ©cupÃ©ration des stations: {e}")
            return []
    
    def get_station_timeseries(self, station_id: str, attr_name: str = "availableBikeNumber", 
                              from_date: str = "2024-01-01T00:00:00", 
                              to_date: str = "2025-01-01T00:00:00") -> Dict[str, Any]:
        """RÃ©cupÃ¨re les donnÃ©es temporelles d'une station"""
        # URL encode the station ID
        encoded_station_id = urllib.parse.quote(station_id, safe='')
        encoded_from_date = urllib.parse.quote(from_date, safe='')
        encoded_to_date = urllib.parse.quote(to_date, safe='')
        
        url = f"{self.BASE_URL}{self.TIMESERIES_ENDPOINT}/{encoded_station_id}/attrs/{attr_name}"
        params = {
            'fromDate': from_date,
            'toDate': to_date
        }
        
        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            # Cache les donnÃ©es
            cache_key = f"{station_id}_{attr_name}_{from_date}_{to_date}"
            self.timeseries_cache[cache_key] = data
            
            print(f"âœ… DonnÃ©es temporelles rÃ©cupÃ©rÃ©es pour {station_id}: {len(data.get('values', []))} points")
            return data
        except requests.RequestException as e:
            print(f"âŒ Erreur pour la station {station_id}: {e}")
            return {}
    
    def analyze_current_status(self) -> pd.DataFrame:
        """Analyse l'Ã©tat actuel de toutes les stations"""
        if not self.stations_data:
            self.get_all_stations()
        
        stations_list = []
        for station in self.stations_data:
            station_info = {
                'id': station['id'],
                'address': station['address']['value']['streetAddress'],
                'locality': station['address']['value']['addressLocality'],
                'available_bikes': station['availableBikeNumber']['value'],
                'free_slots': station['freeSlotNumber']['value'],
                'total_slots': station['totalSlotNumber']['value'],
                'status': station['status']['value'],
                'latitude': station['location']['value']['coordinates'][1],
                'longitude': station['location']['value']['coordinates'][0],
                'last_update': station['availableBikeNumber']['metadata'].get('timestamp', {}).get('value', 'N/A')
            }
            stations_list.append(station_info)
        
        df = pd.DataFrame(stations_list)
        df['occupancy_rate'] = df['available_bikes'] / df['total_slots']
        df['utilization_rate'] = (df['total_slots'] - df['free_slots']) / df['total_slots']
        
        return df
    
    def generate_statistics_report(self, df: pd.DataFrame) -> Dict[str, Any]:
        """GÃ©nÃ¨re un rapport statistique complet"""
        stats = {
            'general': {
                'total_stations': len(df),
                'working_stations': len(df[df['status'] == 'working']),
                'total_bikes': df['available_bikes'].sum(),
                'total_capacity': df['total_slots'].sum(),
                'average_occupancy': df['occupancy_rate'].mean(),
                'median_occupancy': df['occupancy_rate'].median()
            },
            'distribution': {
                'bikes_per_station': {
                    'mean': df['available_bikes'].mean(),
                    'std': df['available_bikes'].std(),
                    'min': df['available_bikes'].min(),
                    'max': df['available_bikes'].max(),
                    'quartiles': df['available_bikes'].quantile([0.25, 0.5, 0.75]).to_dict()
                },
                'capacity_per_station': {
                    'mean': df['total_slots'].mean(),
                    'std': df['total_slots'].std(),
                    'min': df['total_slots'].min(),
                    'max': df['total_slots'].max()
                }
            },
            'extremes': {
                'most_occupied': df.loc[df['occupancy_rate'].idxmax()].to_dict(),
                'least_occupied': df.loc[df['occupancy_rate'].idxmin()].to_dict(),
                'largest_station': df.loc[df['total_slots'].idxmax()].to_dict(),
                'smallest_station': df.loc[df['total_slots'].idxmin()].to_dict()
            }
        }
        
        return stats
    
    def analyze_temporal_patterns(self, station_id: str, days: int = 7) -> Dict[str, Any]:
        """Analyse les patterns temporels d'une station"""
        # Calcul des dates
        to_date = datetime.now()
        from_date = to_date - timedelta(days=days)
        
        from_date_str = from_date.strftime("%Y-%m-%dT%H:%M:%S")
        to_date_str = to_date.strftime("%Y-%m-%dT%H:%M:%S")
        
        # RÃ©cupÃ©ration des donnÃ©es
        data = self.get_station_timeseries(station_id, "availableBikeNumber", from_date_str, to_date_str)
        
        if not data or 'values' not in data:
            return {}
        
        # CrÃ©ation du DataFrame
        df = pd.DataFrame({
            'timestamp': pd.to_datetime(data['index']),
            'available_bikes': data['values']
        })
        
        df['hour'] = df['timestamp'].dt.hour
        df['day_of_week'] = df['timestamp'].dt.day_name()
        df['date'] = df['timestamp'].dt.date
        
        analysis = {
            'hourly_patterns': df.groupby('hour')['available_bikes'].agg(['mean', 'std', 'min', 'max']).to_dict(),
            'daily_patterns': df.groupby('day_of_week')['available_bikes'].agg(['mean', 'std']).to_dict(),
            'trends': {
                'overall_trend': np.polyfit(range(len(df)), df['available_bikes'], 1)[0],
                'peak_hour': df.groupby('hour')['available_bikes'].mean().idxmin(),
                'low_hour': df.groupby('hour')['available_bikes'].mean().idxmax()
            }
        }
        
        return analysis
    
    def create_visualizations(self, df: pd.DataFrame, output_dir: str = "visualizations"):
        """CrÃ©e des visualisations des donnÃ©es"""
        os.makedirs(output_dir, exist_ok=True)
        
        # Style des graphiques
        plt.style.use('seaborn-v0_8')
        
        # 1. Distribution des vÃ©los disponibles
        plt.figure(figsize=(10, 6))
        plt.hist(df['available_bikes'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title('Distribution du nombre de vÃ©los disponibles par station')
        plt.xlabel('Nombre de vÃ©los disponibles')
        plt.ylabel('Nombre de stations')
        plt.grid(True, alpha=0.3)
        plt.savefig(f"{output_dir}/bikes_distribution.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. Taux d'occupation par station
        plt.figure(figsize=(12, 8))
        plt.scatter(df['longitude'], df['latitude'], c=df['occupancy_rate'], 
                   cmap='RdYlGn_r', s=df['total_slots']*3, alpha=0.7)
        plt.colorbar(label='Taux d\'occupation')
        plt.title('Taux d\'occupation des stations VÃ©lomagg (taille = capacitÃ©)')
        plt.xlabel('Longitude')
        plt.ylabel('Latitude')
        plt.grid(True, alpha=0.3)
        plt.savefig(f"{output_dir}/occupancy_map.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. Top 10 des stations les plus/moins occupÃ©es
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Plus occupÃ©es
        top_occupied = df.nlargest(10, 'occupancy_rate')
        ax1.barh(range(len(top_occupied)), top_occupied['occupancy_rate'])
        ax1.set_yticks(range(len(top_occupied)))
        ax1.set_yticklabels([addr[:30] + '...' if len(addr) > 30 else addr 
                            for addr in top_occupied['address']], fontsize=8)
        ax1.set_title('Top 10 stations les plus occupÃ©es')
        ax1.set_xlabel('Taux d\'occupation')
        
        # Moins occupÃ©es
        least_occupied = df.nsmallest(10, 'occupancy_rate')
        ax2.barh(range(len(least_occupied)), least_occupied['occupancy_rate'])
        ax2.set_yticks(range(len(least_occupied)))
        ax2.set_yticklabels([addr[:30] + '...' if len(addr) > 30 else addr 
                            for addr in least_occupied['address']], fontsize=8)
        ax2.set_title('Top 10 stations les moins occupÃ©es')
        ax2.set_xlabel('Taux d\'occupation')
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/top_stations.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… Visualisations sauvegardÃ©es dans le dossier '{output_dir}'")
    
    def export_data(self, df: pd.DataFrame, stats: Dict[str, Any], filename: str = "velomagg_analysis"):
        """Exporte les donnÃ©es et statistiques"""
        # Export CSV
        df.to_csv(f"{filename}.csv", index=False, encoding='utf-8')
        
        # Export JSON des statistiques
        with open(f"{filename}_stats.json", 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… DonnÃ©es exportÃ©es: {filename}.csv et {filename}_stats.json")

def main():
    """Fonction principale"""
    print("ğŸš´ DÃ©marrage de l'analyse VÃ©lomagg Montpellier")
    
    analyzer = VelomaggAnalyzer()
    
    # 1. RÃ©cupÃ©ration et analyse des donnÃ©es actuelles
    print("\nğŸ“Š Analyse de l'Ã©tat actuel des stations...")
    current_df = analyzer.analyze_current_status()
    
    # 2. GÃ©nÃ©ration des statistiques
    print("\nğŸ“ˆ GÃ©nÃ©ration du rapport statistique...")
    stats = analyzer.generate_statistics_report(current_df)
    
    # 3. Affichage des rÃ©sultats principaux
    print("\n" + "="*50)
    print("ğŸ“‹ RÃ‰SUMÃ‰ EXÃ‰CUTIF")
    print("="*50)
    print(f"ğŸ¢ Nombre total de stations: {stats['general']['total_stations']}")
    print(f"ğŸš´ Nombre total de vÃ©los: {stats['general']['total_bikes']}")
    print(f"ğŸ“ Stations en fonctionnement: {stats['general']['working_stations']}")
    print(f"ğŸ“Š Taux d'occupation moyen: {stats['general']['average_occupancy']:.1%}")
    print(f"ğŸ¯ CapacitÃ© totale: {stats['general']['total_capacity']} places")
    
    print(f"\nğŸ† Station la plus occupÃ©e: {stats['extremes']['most_occupied']['address']}")
    print(f"   ğŸ“ˆ Taux: {stats['extremes']['most_occupied']['occupancy_rate']:.1%}")
    
    print(f"\nğŸ¯ Station la moins occupÃ©e: {stats['extremes']['least_occupied']['address']}")
    print(f"   ğŸ“‰ Taux: {stats['extremes']['least_occupied']['occupancy_rate']:.1%}")
    
    # 4. CrÃ©ation des visualisations
    print("\nğŸ“Š CrÃ©ation des visualisations...")
    analyzer.create_visualizations(current_df)
    
    # 5. Export des donnÃ©es
    print("\nğŸ’¾ Export des donnÃ©es...")
    analyzer.export_data(current_df, stats)
    
    # 6. Analyse temporelle d'une station exemple
    if len(current_df) > 0:
        sample_station = current_df.iloc[0]['id']
        print(f"\nâ° Analyse temporelle de la station exemple: {sample_station}")
        temporal_analysis = analyzer.analyze_temporal_patterns(sample_station, days=7)
        if temporal_analysis:
            print(f"ğŸ• Heure de pointe: {temporal_analysis['trends']['peak_hour']}h")
            print(f"ğŸ• Heure creuse: {temporal_analysis['trends']['low_hour']}h")
    
    print("\nâœ… Analyse terminÃ©e avec succÃ¨s!")
    print("ğŸ“ Fichiers gÃ©nÃ©rÃ©s:")
    print("   - velomagg_analysis.csv (donnÃ©es dÃ©taillÃ©es)")
    print("   - velomagg_analysis_stats.json (statistiques)")
    print("   - visualizations/ (graphiques)")

if __name__ == "__main__":
    main()
