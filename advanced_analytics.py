#!/usr/bin/env python3
"""
Analyses avanc√©es pour les donn√©es V√©lomagg
Module d'extensions pour des analyses sp√©cialis√©es
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple
import warnings
warnings.filterwarnings('ignore')

class AdvancedAnalytics:
    """Analyses avanc√©es des donn√©es V√©lomagg"""
    
    def __init__(self, analyzer):
        self.analyzer = analyzer
    
    def predict_peak_hours(self, station_id: str, days: int = 30) -> Dict[str, Any]:
        """Pr√©dit les heures de pointe bas√©es sur l'historique"""
        data = self.analyzer.get_station_timeseries(
            station_id, "availableBikeNumber", 
            (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%dT%H:%M:%S"),
            datetime.now().strftime("%Y-%m-%dT%H:%M:%S")
        )
        
        if not data or 'values' not in data:
            return {}
        
        df = pd.DataFrame({
            'timestamp': pd.to_datetime(data['index']),
            'available_bikes': data['values']
        })
        
        df['hour'] = df['timestamp'].dt.hour
        df['day_of_week'] = df['timestamp'].dt.dayofweek
        df['is_weekend'] = df['day_of_week'].isin([5, 6])
        
        # Calcul de l'occupation inverse (plus de v√©los pris = heure de pointe)
        max_bikes = df['available_bikes'].max()
        df['usage_intensity'] = max_bikes - df['available_bikes']
        
        # Patterns par type de jour
        weekday_pattern = df[~df['is_weekend']].groupby('hour')['usage_intensity'].mean()
        weekend_pattern = df[df['is_weekend']].groupby('hour')['usage_intensity'].mean()
        
        return {
            'weekday_peaks': {
                'morning_peak': weekday_pattern.idxmax(),
                'evening_peak': weekday_pattern[weekday_pattern.index > 12].idxmax(),
                'pattern': weekday_pattern.to_dict()
            },
            'weekend_peaks': {
                'main_peak': weekend_pattern.idxmax(),
                'pattern': weekend_pattern.to_dict()
            },
            'predictions': {
                'next_weekday_peak': weekday_pattern.idxmax(),
                'next_weekend_peak': weekend_pattern.idxmax()
            }
        }
    
    def calculate_station_efficiency(self, df: pd.DataFrame) -> pd.DataFrame:
        """Calcule l'efficacit√© des stations"""
        df_copy = df.copy()
        
        # Taux d'utilisation (v√©los + places occup√©es / capacit√© totale)
        df_copy['utilization_rate'] = (df_copy['total_slots'] - df_copy['free_slots']) / df_copy['total_slots']
        
        # Score d'√©quilibre (proche de 50% = optimal)
        df_copy['balance_score'] = 1 - abs(df_copy['occupancy_rate'] - 0.5) * 2
        
        # Score de disponibilit√© (√©vite les stations vides/pleines)
        df_copy['availability_score'] = np.where(
            (df_copy['available_bikes'] == 0) | (df_copy['free_slots'] == 0), 0, 1
        )
        
        # Score d'efficacit√© global
        df_copy['efficiency_score'] = (
            df_copy['balance_score'] * 0.4 + 
            df_copy['availability_score'] * 0.3 +
            df_copy['utilization_rate'] * 0.3
        )
        
        return df_copy
    
    def identify_problem_stations(self, df: pd.DataFrame) -> Dict[str, List[Dict]]:
        """Identifie les stations probl√©matiques"""
        df_eff = self.calculate_station_efficiency(df)
        
        problems = {
            'always_empty': df_eff[df_eff['available_bikes'] == 0].to_dict('records'),
            'always_full': df_eff[df_eff['free_slots'] == 0].to_dict('records'),
            'low_efficiency': df_eff[df_eff['efficiency_score'] < 0.3].to_dict('records'),
            'inactive': df_eff[df_eff['status'] != 'working'].to_dict('records'),
            'oversized': df_eff[df_eff['utilization_rate'] < 0.1].to_dict('records'),
            'undersized': df_eff[df_eff['utilization_rate'] > 0.9].to_dict('records')
        }
        
        return problems
    
    def calculate_coverage_analysis(self, df: pd.DataFrame, radius_km: float = 0.5) -> Dict[str, Any]:
        """Analyse de couverture g√©ographique"""
        from math import radians, cos, sin, asin, sqrt
        
        def haversine(lon1, lat1, lon2, lat2):
            """Calcule la distance entre deux points GPS"""
            lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])
            dlon = lon2 - lon1
            dlat = lat2 - lat1
            a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
            c = 2 * asin(sqrt(a))
            r = 6371  # Rayon terrestre en km
            return c * r
        
        # Calcul des distances entre stations
        distances = []
        coverage_zones = []
        
        for i, station1 in df.iterrows():
            nearby_stations = 0
            for j, station2 in df.iterrows():
                if i != j:
                    dist = haversine(
                        station1['longitude'], station1['latitude'],
                        station2['longitude'], station2['latitude']
                    )
                    if dist <= radius_km:
                        nearby_stations += 1
                    distances.append(dist)
            
            coverage_zones.append({
                'station_id': station1['id'],
                'address': station1['address'],
                'nearby_stations': nearby_stations,
                'coverage_density': nearby_stations / (np.pi * radius_km**2)
            })
        
        coverage_df = pd.DataFrame(coverage_zones)
        
        return {
            'average_distance': np.mean(distances),
            'min_distance': np.min(distances),
            'isolated_stations': coverage_df[coverage_df['nearby_stations'] == 0].to_dict('records'),
            'dense_areas': coverage_df[coverage_df['nearby_stations'] > 5].to_dict('records'),
            'coverage_stats': {
                'mean_density': coverage_df['coverage_density'].mean(),
                'std_density': coverage_df['coverage_density'].std()
            }
        }
    
    def generate_optimization_recommendations(self, df: pd.DataFrame) -> Dict[str, List[str]]:
        """G√©n√®re des recommandations d'optimisation"""
        problems = self.identify_problem_stations(df)
        df_eff = self.calculate_station_efficiency(df)
        
        recommendations = {
            'urgent': [],
            'maintenance': [],
            'capacity': [],
            'deployment': []
        }
        
        # Recommandations urgentes
        if len(problems['inactive']) > 0:
            recommendations['urgent'].append(
                f"üö® {len(problems['inactive'])} stations hors service n√©cessitent une intervention imm√©diate"
            )
        
        if len(problems['always_empty']) > 0:
            recommendations['urgent'].append(
                f"‚ö†Ô∏è {len(problems['always_empty'])} stations compl√®tement vides (redistribution urgente)"
            )
        
        if len(problems['always_full']) > 0:
            recommendations['urgent'].append(
                f"‚ö†Ô∏è {len(problems['always_full'])} stations compl√®tement pleines (retrait urgent)"
            )
        
        # Recommandations de maintenance
        low_eff_count = len(problems['low_efficiency'])
        if low_eff_count > len(df) * 0.1:
            recommendations['maintenance'].append(
                f"üîß {low_eff_count} stations ont une faible efficacit√© (>10% du r√©seau)"
            )
        
        # Recommandations de capacit√©
        if len(problems['oversized']) > 0:
            recommendations['capacity'].append(
                f"üìâ {len(problems['oversized'])} stations sous-utilis√©es (r√©duction possible)"
            )
        
        if len(problems['undersized']) > 0:
            recommendations['capacity'].append(
                f"üìà {len(problems['undersized'])} stations sur-utilis√©es (extension recommand√©e)"
            )
        
        # Recommandations de d√©ploiement
        avg_efficiency = df_eff['efficiency_score'].mean()
        if avg_efficiency < 0.6:
            recommendations['deployment'].append(
                f"üéØ Efficacit√© r√©seau globale faible ({avg_efficiency:.1%}) - r√©√©quilibrage n√©cessaire"
            )
        
        return recommendations

class ReportGenerator:
    """G√©n√©rateur de rapports avanc√©s"""
    
    def __init__(self, analyzer, advanced_analytics):
        self.analyzer = analyzer
        self.advanced = advanced_analytics
    
    def generate_executive_summary(self, df: pd.DataFrame) -> str:
        """G√©n√®re un r√©sum√© ex√©cutif"""
        stats = self.analyzer.generate_statistics_report(df)
        problems = self.advanced.identify_problem_stations(df)
        recommendations = self.advanced.generate_optimization_recommendations(df)
        
        summary = f"""
üìä RAPPORT EX√âCUTIF V√âLOMAGG MONTPELLIER
{'='*50}

üéØ INDICATEURS CL√âS
‚Ä¢ R√©seau: {stats['general']['total_stations']} stations ({stats['general']['working_stations']} actives)
‚Ä¢ Flotte: {stats['general']['total_bikes']} v√©los sur {stats['general']['total_capacity']} places
‚Ä¢ Taux d'occupation: {stats['general']['average_occupancy']:.1%} (cible: 40-60%)
‚Ä¢ Performance r√©seau: {'üü¢ BONNE' if stats['general']['average_occupancy'] > 0.4 and stats['general']['average_occupancy'] < 0.6 else 'üü° √Ä SURVEILLER' if stats['general']['average_occupancy'] > 0.2 else 'üî¥ CRITIQUE'}

‚ö†Ô∏è ALERTES ({len(problems['inactive']) + len(problems['always_empty']) + len(problems['always_full'])} urgentes)
‚Ä¢ Stations hors service: {len(problems['inactive'])}
‚Ä¢ Stations vides: {len(problems['always_empty'])}
‚Ä¢ Stations pleines: {len(problems['always_full'])}
‚Ä¢ Efficacit√© faible: {len(problems['low_efficiency'])}

üèÜ PERFORMANCES
‚Ä¢ Meilleure station: {stats['extremes']['most_occupied']['address'][:40]}... ({stats['extremes']['most_occupied']['occupancy_rate']:.1%})
‚Ä¢ Station critique: {stats['extremes']['least_occupied']['address'][:40]}... ({stats['extremes']['least_occupied']['occupancy_rate']:.1%})

üí° ACTIONS PRIORITAIRES
"""
        
        for category, items in recommendations.items():
            if items:
                summary += f"\n{category.upper()}:\n"
                for item in items[:3]:  # Top 3 par cat√©gorie
                    summary += f"  ‚Ä¢ {item}\n"
        
        return summary
    
    def generate_detailed_report(self, df: pd.DataFrame, output_file: str = "rapport_detaille.txt"):
        """G√©n√®re un rapport d√©taill√© complet"""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(self.generate_executive_summary(df))
            f.write("\n\n" + "="*50)
            f.write("\nRAPPORT D√âTAILL√â\n")
            f.write("="*50)
            
            # Analyse par quartiles
            f.write(f"\n\nüìà ANALYSE PAR QUARTILES\n")
            f.write(f"Q1 (25%): {df['occupancy_rate'].quantile(0.25):.1%}\n")
            f.write(f"Q2 (50%): {df['occupancy_rate'].quantile(0.5):.1%}\n")
            f.write(f"Q3 (75%): {df['occupancy_rate'].quantile(0.75):.1%}\n")
            
            # Top/Bottom stations
            f.write(f"\n\nüèÜ TOP 10 STATIONS LES PLUS EFFICACES\n")
            df_eff = self.advanced.calculate_station_efficiency(df)
            top_stations = df_eff.nlargest(10, 'efficiency_score')
            for i, station in top_stations.iterrows():
                f.write(f"{station['address'][:50]:<50} {station['efficiency_score']:.1%}\n")
            
            f.write(f"\n\n‚ö†Ô∏è TOP 10 STATIONS √Ä AM√âLIORER\n")
            bottom_stations = df_eff.nsmallest(10, 'efficiency_score')
            for i, station in bottom_stations.iterrows():
                f.write(f"{station['address'][:50]:<50} {station['efficiency_score']:.1%}\n")
        
        print(f"‚úÖ Rapport d√©taill√© sauvegard√©: {output_file}")

def main_advanced():
    """Fonction principale pour les analyses avanc√©es"""
    from main import VelomaggAnalyzer
    
    print("üî¨ D√©marrage des analyses avanc√©es V√©lomagg")
    
    # Initialisation
    analyzer = VelomaggAnalyzer()
    advanced = AdvancedAnalytics(analyzer)
    reporter = ReportGenerator(analyzer, advanced)
    
    # R√©cup√©ration des donn√©es
    df = analyzer.analyze_current_status()
    
    # Analyses avanc√©es
    print("\nüß† Calcul de l'efficacit√© des stations...")
    df_efficiency = advanced.calculate_station_efficiency(df)
    
    print("üîç Identification des probl√®mes...")
    problems = advanced.identify_problem_stations(df)
    
    print("üìç Analyse de couverture g√©ographique...")
    coverage = advanced.calculate_coverage_analysis(df)
    
    print("üí° G√©n√©ration des recommandations...")
    recommendations = advanced.generate_optimization_recommendations(df)
    
    # Rapport ex√©cutif
    print("\nüìä G√©n√©ration du rapport ex√©cutif...")
    exec_summary = reporter.generate_executive_summary(df)
    print(exec_summary)
    
    # Rapport d√©taill√©
    print("\nüìÑ G√©n√©ration du rapport d√©taill√©...")
    reporter.generate_detailed_report(df)
    
    # Analyse temporelle sur quelques stations
    print("\n‚è∞ Analyse des patterns temporels...")
    sample_stations = df.head(3)['id'].tolist()
    for station_id in sample_stations:
        peaks = advanced.predict_peak_hours(station_id, days=7)
        if peaks:
            print(f"Station {station_id}: Pic semaine {peaks['weekday_peaks']['morning_peak']}h-{peaks['weekday_peaks']['evening_peak']}h")
    
    print("\n‚úÖ Analyses avanc√©es termin√©es!")

if __name__ == "__main__":
    main_advanced()
